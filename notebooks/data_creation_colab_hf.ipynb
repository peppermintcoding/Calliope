{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers.git\n",
        "!git clone https://github.com/peppermintcoding/Calliope.git\n",
        "!pip install -U -q autoawq accelerate openai"
      ],
      "metadata": {
        "id": "l3dffCvoQSLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnNtIHc3QC88"
      },
      "outputs": [],
      "source": [
        "from transformers import AwqConfig, AutoModelForCausalLM, AutoTokenizer\n",
        "import time\n",
        "\n",
        "# model_name_or_path = \"TheBloke/UNA-TheBeagle-7B-v1-AWQ\"\n",
        "model_name_or_path = \"TheBloke/OpenHermes-2.5-Mistral-7B-AWQ\"\n",
        "# model_name_or_path = \"TheBloke/Nous-Hermes-2-SOLAR-10.7B-AWQ\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name_or_path,\n",
        "    low_cpu_mem_usage=True,\n",
        "    device_map=\"cuda\")\n",
        "model.config.pad_token_id = tokenizer.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Calliope.data.llm_poetry import FAMOUS_POETS, POEM_TOPICS, THINGS\n",
        "import numpy as np\n",
        "\n",
        "def create_random_prompt():\n",
        "    poet = np.random.choice(FAMOUS_POETS)\n",
        "    topic = np.random.choice(POEM_TOPICS)\n",
        "    thing = np.random.choice(THINGS, size=2, replace=False)\n",
        "\n",
        "    system_prompt = f\"You are a poet like {poet}. You are a very skilled poet, fun, whymsical, extraordinary gifted.\"\n",
        "    user_prompt = f\"Write a poem about {topic} and incorporate {thing[0]} and {thing[1]} into it.\"\n",
        "    return (\n",
        "        \"<|im_start|>system\\n\"\n",
        "        f\"{system_prompt}<|im_end|>\\n\"\n",
        "        \"<|im_start|>user\\n\"\n",
        "        f\"{user_prompt}<|im_end|>\\n\"\n",
        "        \"<|im_start|>assistant\\n\"\n",
        "    )"
      ],
      "metadata": {
        "id": "5KNYP3JSOWrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "id": "tX_gOVijTKKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "poems = []\n",
        "pbar = tqdm(range(1, 100))\n",
        "for i in pbar:\n",
        "  prompts = [create_random_prompt() for _ in range(35)]\n",
        "  tokens = tokenizer(prompts, return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
        "\n",
        "  start_time = time.time()\n",
        "  generation_output = model.generate(**tokens, do_sample=True, temperature=0.95, max_length=2048)\n",
        "  num_tokens = 0\n",
        "  for j, output in enumerate(generation_output):\n",
        "    num_tokens += len(output[len(tokens[j]):])\n",
        "    poems.append([model_name_or_path, prompts[j], tokenizer.decode(output[len(tokens[j]):], skip_special_tokens=True)])\n",
        "  end_time = time.time()\n",
        "  pbar.set_description(f\"Generating at {num_tokens / (end_time - start_time):.2f} Tokens/s\")\n",
        "  if i % 10 == 0:\n",
        "    df = pd.DataFrame(data=poems, columns=[\"model_name\", \"prompt\", \"text\"])\n",
        "    df.to_csv(\n",
        "      \"../gdrive/MyDrive/Calliope/llm_poems.csv\",\n",
        "      index=False,\n",
        "      mode=\"a\",\n",
        "      header=False,\n",
        "    )\n",
        "    poems = []\n",
        "\n",
        "# add remainder\n",
        "df = pd.DataFrame(data=poems, columns=[\"model_name\", \"prompt\", \"text\"])\n",
        "df.to_csv(\n",
        "  \"../gdrive/MyDrive/Calliope/llm_poems.csv\",\n",
        "  index=False,\n",
        "  mode=\"a\",\n",
        "  header=False,\n",
        ")"
      ],
      "metadata": {
        "id": "9D_4bQl5S5oS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"../gdrive/MyDrive/Calliope/llm_poems.csv\")\n",
        "print(f\"Number of words: {df['text'].apply(lambda x: len(x.split())).sum():,}\")"
      ],
      "metadata": {
        "id": "d0wvl8P3nrHr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}